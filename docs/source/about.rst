About
=====

`SciXTracer` is a python library to ease interaction with datasets all along the data
science journey. It aims at being a generic API for read and write data
(array, table, values, labels) with associated annotations and metadata. `SciXTracer`
API is based on a plugin architecture to allow using any storage depending on the user needs.

Why `SciXTracer`
----------------

- When developing data science workflow, it is a pain to write dedicated code to interact with data
  storage
- When deploying a data science workflows, it is a pain to re-write the data processing script to
  match the infrastructure API
- Ensuring traceability (FAIR principles), of data and results is an extra-work for data-scientists
  to include code for metadata generation in the analysis scripts

SciXTracer tends to encapsulate storage, deployment, and traceability into a unique API.
Write one code, deploy it on any AI platforms.

Principles
----------

Principle 1: Fair principles first
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The aim of `SciXTracer` is to avoid loss of information and guaranty traceability of
any result generated by any data science pipeline.
A data science pipeline writen using `SciXTracer` stores all the results and associated
metadata without asking extra (error prone) work

Principle 2: Focus on simple API and usability
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Data science pipeline should not care about how data are stored, how metadata are stored,
how the code is parallelized. Data science pipeline should be **over simple** easy to write
and easy to read. It should focus on the data science logic and not on backend or storage logic.

Only high level methods should be used to interact with the storage like ``get_dataset``,
``get_data``, ``set_data``...

Principle 3: Interoperability
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Data science API should not re-invent data structure, but be compatible with the existing
ecosystem for an optimal data scientist experience. Array structure should be compatible
with Numpy, PyTorch, TensorFLow, Dask..., Table structure should be compatible with Pandas,
SPolars, Spark...